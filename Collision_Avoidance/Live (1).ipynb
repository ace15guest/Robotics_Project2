{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from jetbot import Robot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model object that uses alexnet as a constructor for image classification\n",
    "# Alexnet is a CNN \n",
    "# We will not use a pretrained version although \n",
    "#https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "#Applies a linear transformation to the data \n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will load in the pytorch model created in the training in the train_model section\n",
    "# load deserializes the data \n",
    "# the learnable parameters are weights and biases \n",
    "# We have convolutional layers\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The device to load our tensor (vector) into memory\n",
    "# Basically moving the model weights and biases from the CPU to GPU\n",
    "# so we can look at high resolution vid/imgs\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cca1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section will make the model that we trained match the camera\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "#\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    \"\"\"\n",
    "    camera_value: image received from the neural network\n",
    "    return x: a suitable ipnut to the neural network\n",
    "    \"\"\"\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    #Convert BGR to RGB\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create our camera object and widgets to show the camera image and control the speed\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "speed_slider = widgets.FloatSlider(description='speed', min=0.0, max=0.5, value=0.0, step=0.01, orientation='horizontal')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([image, blocked_slider]), speed_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create robot object\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised Logistic learning (Classification)\n",
    "#Using Alexnet CNN\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it \n",
    "    #sums to 1 (which makes it a probability distribution)\n",
    "    # Basically zi = (xi – min(x)) / (max(x) – min(x)) where z is the normalized value\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.5:\n",
    "        robot.left(-speed_slider.value)\n",
    "    else:\n",
    "        robot.forward(-speed_slider.value)\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d595b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attatches the each frame of the camera to the update fcn\n",
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4aee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
